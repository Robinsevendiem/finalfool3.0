import tushare as ts
import pandas as pd
import os
import time
from datetime import datetime, timedelta

import os
import sys

# --- Config ---
# Try to get from Streamlit Secrets first, then Env Var, then fallback (for local dev)
TS_TOKEN = None

try:
    import streamlit as st
    # Check if secrets file exists or if we are running in a context where secrets might be available
    # But st.secrets access might raise FileNotFoundError if no .streamlit/secrets.toml exists locally
    try:
        if hasattr(st, 'secrets') and 'TS_TOKEN' in st.secrets:
            TS_TOKEN = st.secrets['TS_TOKEN']
    except Exception:
        pass # Secrets not available
except ImportError:
    pass

# Fallback to Env Var (Passed by app.py subprocess or set in CI/CD)
if not TS_TOKEN:
    TS_TOKEN = os.environ.get('TS_TOKEN', '') # Please set TS_TOKEN in environment or streamlit secrets

DATA_DIR = 'market_data'

NAME_MAP = {
    '513100.SH': 'Á∫≥Êåá100',
    '513520.SH': 'Êó•ÁªèETF',
    '513500.SH': 'Ê†áÊôÆ500',
    '159915.SZ': 'Âàõ‰∏öÊùø',
    '588120.SH': 'ÁßëÂàõÊùø',
    '588000.SH': 'ÁßëÂàõÊùø', 
    '510180.SH': '‰∏äËØÅ180',
    '518880.SH': 'ÈªÑÈáëETF',
    '511090.SH': '30Âπ¥ÂõΩÂÄ∫',
    '161129.SZ': 'ÂçóÊñπÂéüÊ≤π',
    '501018.SH': 'ÂçóÊñπÂéüÊ≤π'
}

# Mapping for Tushare: Some ETFs might need different codes or handling
# Tushare uses '513100.SH' format directly.
TARGET_CODES = list(NAME_MAP.keys())

def update_market_data():
    print("üöÄ ÂºÄÂßãÊõ¥Êñ∞Â∏ÇÂú∫Êï∞ÊçÆ...")
    
    # 1. Init Tushare
    # Tushare tries to write to ~/.tushare/token.csv or current dir.
    # In restricted env, we set token in pro_api directly to avoid file write.
    pro = ts.pro_api(TS_TOKEN)
    
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
        
    today = datetime.now().strftime('%Y%m%d')
    start_date = '20230101' # Default start if no file
    
    updated_count = 0
    
    for code in TARGET_CODES:
        name = NAME_MAP[code]
        filename = f"{code}_{name}.csv"
        # Sanitize filename
        filename = filename.replace('/', '_')
        filepath = os.path.join(DATA_DIR, filename)
        
        # Check existing file to find last date
        if os.path.exists(filepath):
            try:
                df_old = pd.read_csv(filepath)
                # Ensure date format
                if 'trade_date' in df_old.columns:
                    df_old['trade_date'] = df_old['trade_date'].astype(str)
                    last_date = df_old['trade_date'].max()
                    
                    # Convert to datetime to add 1 day
                    last_dt = datetime.strptime(last_date, '%Y%m%d')
                    fetch_start = (last_dt + timedelta(days=1)).strftime('%Y%m%d')
                else:
                    fetch_start = start_date
            except:
                fetch_start = start_date
                df_old = pd.DataFrame()
        else:
            df_old = pd.DataFrame()
            fetch_start = start_date
            
        if fetch_start > today:
            print(f"‚úÖ {name} ({code}) Â∑≤ÊòØÊúÄÊñ∞„ÄÇ")
            continue
            
        print(f"üì• Êõ¥Êñ∞ {name} ({code}) | ËåÉÂõ¥: {fetch_start} -> {today}")
        
        try:
            # Fetch Daily Data (Price)
            df_new = pro.fund_daily(ts_code=code, start_date=fetch_start, end_date=today)
            
            if df_new.empty:
                print(f"   ‚ö†Ô∏è Êó†Êñ∞Êï∞ÊçÆ")
                continue
                
            # Fetch Adj Factor (for QFQ)
            df_adj = pro.fund_adj(ts_code=code, start_date=fetch_start, end_date=today)
            
            if not df_adj.empty:
                # Merge to calc QFQ
                # Tushare fund_daily has: close, open, high, low, pre_close, change, pct_chg, vol, amount
                # Need to calculate close_qfq. 
                # Formula: price * adj_factor
                df_new = pd.merge(df_new, df_adj[['trade_date', 'adj_factor']], on='trade_date', how='left')
                df_new['adj_factor'] = df_new['adj_factor'].fillna(1.0)
                
                cols = ['open', 'high', 'low', 'close', 'pre_close']
                for c in cols:
                    df_new[f'{c}_qfq'] = df_new[c] * df_new['adj_factor']
            else:
                # Fallback if no adj factor (rare for ETFs)
                cols = ['open', 'high', 'low', 'close', 'pre_close']
                for c in cols:
                    df_new[f'{c}_qfq'] = df_new[c]
            
            # Combine
            if not df_old.empty:
                df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=['trade_date']).sort_values('trade_date')
            else:
                df_final = df_new.sort_values('trade_date')
                
            # Save
            df_final.to_csv(filepath, index=False)
            print(f"   üíæ Â∑≤‰øùÂ≠ò ({len(df_new)} Êù°Êñ∞ËÆ∞ÂΩï)")
            updated_count += 1
            
            # Rate limit protection
            time.sleep(0.3)
            
        except Exception as e:
            print(f"   ‚ùå Êõ¥Êñ∞Â§±Ë¥•: {e}")
            
    print(f"\nüéâ Êõ¥Êñ∞ÂÆåÊàê! ÂÖ±Êõ¥Êñ∞ {updated_count} ‰∏™Êñá‰ª∂„ÄÇ")
    return updated_count

if __name__ == '__main__':
    update_market_data()
